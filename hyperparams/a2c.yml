atari:
  policy: 'CnnPolicy'
  n_envs: 16
  n_timesteps: !!float 1e7

CartPole-v1:
  n_envs: 8
  n_timesteps: !!float 5e5
  policy: 'MlpPolicy'
  ent_coef: 0.0

LunarLander-v2:
  n_envs: 8
  n_timesteps: !!float 2e5
  policy: 'MlpPolicy'
  gamma: 0.995
  n_steps: 5
  learning_rate: lin_0.00083
  ent_coef: 0.00001

MountainCar-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  ent_coef: .0

Acrobot-v1:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e5
  policy: 'MlpPolicy'
  ent_coef: .0

Pendulum-v0:
  n_envs: 8
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  ent_coef: 0.0
  gamma: 0.95

LunarLanderContinuous-v2:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e6
  policy: 'MlpPolicy'
  gamma: 0.999
  ent_coef: 0.001
  learning_rate: lin_7e-4

MountainCarContinuous-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  ent_coef: 0.0

BipedalWalker-v2:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 5e6
  policy: 'MlpPolicy'
  ent_coef: 0.0
  learning_rate: lin_7e-4

HalfCheetahBulletEnv-v0:
  env_wrapper: utils.wrappers.TimeFeatureWrapper
  normalize: true
  n_envs: 4
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  ent_coef: 0.0
  max_grad_norm: 0.8
  n_steps: 32
  gae_lambda: 0.9
  vf_coef: 0.4
  gamma: 0.99
  use_rms_prop: True
  normalize_advantage: False
  learning_rate: lin_0.00096
  use_sde: True
  policy_kwargs: "dict(log_std_init=-2, ortho_init=False, net_arch=[dict(pi=[64, 64], vf=[64, 64])])"
  # policy_kwargs: "dict(log_std_init=-1, ortho_init=False, net_arch=[dict(pi=[256, 256], vf=[256, 256])])"

BipedalWalkerHardcore-v2:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 10e7
  policy: 'MlpPolicy'
  frame_stack: 4
  ent_coef: 0.001
  learning_rate: lin_7e-4

Walker2DBulletEnv-v0:
  normalize: true
  n_envs: 4
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  ent_coef: 0.0
  n_steps: 32
  vf_coef: 0.5
  gamma: 0.99
  learning_rate: lin_0.002

AntBulletEnv-v0:
  normalize: true
  n_envs: 4
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  ent_coef: 0.0
  n_steps: 32
  vf_coef: 0.5
  gamma: 0.99
  learning_rate: lin_0.002

HopperBulletEnv-v0:
  normalize: true
  n_envs: 4
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  ent_coef: 0.0
  n_steps: 32
  vf_coef: 0.5
  gamma: 0.99
  learning_rate: lin_0.002

# Not working yet
ReacherBulletEnv-v0:
  normalize: true
  n_envs: 8
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  ent_coef: 0.001
  n_steps: 32
  vf_coef: 0.5
  gamma: 0.99
  learning_rate: lin_0.002
